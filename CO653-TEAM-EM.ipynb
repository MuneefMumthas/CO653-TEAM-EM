{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgEewqvwp5Gz"
      },
      "source": [
        "CO653 - Learning Machines and Intelligent Agents\n",
        "\n",
        "Team mates:\n",
        "\n",
        "Muneef - 22206529\n",
        "\n",
        "Entwan - 22135347\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FR--AijSp5G0"
      },
      "outputs": [],
      "source": [
        "#Importing\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import seaborn as sns\n",
        "from sklearn.utils import resample\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "-NdM5uDSqTUG",
        "outputId": "27f0c729-6cda-43b0-ece9-5ed9cc3c5f2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bH0HpwhSp5G2"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('/content/drive/MyDrive/Loan_train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/Loan_test.csv')\n",
        "\n",
        "train = pd.DataFrame(train)\n",
        "test = pd.DataFrame(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09mBbOMxp5G2"
      },
      "outputs": [],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KOn8t0XHp5G2"
      },
      "outputs": [],
      "source": [
        "train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3sSFq8Wp5G3"
      },
      "outputs": [],
      "source": [
        "test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5r62WhoXp5G3"
      },
      "outputs": [],
      "source": [
        "train.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GxREmFFPp5G3"
      },
      "outputs": [],
      "source": [
        "test.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0JXQzobOp5G3"
      },
      "outputs": [],
      "source": [
        "# Calculate the percentage of missing values per column\n",
        "missing_percentage = train.isnull().mean() * 100\n",
        "\n",
        "# Display columns with more than 0% missing values\n",
        "print(missing_percentage[missing_percentage > 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0mYgHeCp5G3"
      },
      "outputs": [],
      "source": [
        "# Calculate the percentage of missing values per column\n",
        "missing_percentage = test.isnull().mean() * 100\n",
        "\n",
        "# Display columns with more than 0% missing values\n",
        "print(missing_percentage[missing_percentage > 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ddu-JT5p5G3"
      },
      "outputs": [],
      "source": [
        "missing = train[train.isnull().any(axis=1)]\n",
        "missing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rk6GlkRmp5G4"
      },
      "outputs": [],
      "source": [
        "def handle_missing_values(data, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Handles missing values in a dataset:\n",
        "    - Drops columns with more than a specified threshold of missing values.\n",
        "    - Fills remaining missing values with median for numeric columns and mode for categorical columns.\n",
        "\n",
        "    Parameters:\n",
        "        data (pd.DataFrame): The input dataset.\n",
        "        threshold (float): The proportion of missing values above which columns are dropped (default 0.5).\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: The cleaned dataset.\n",
        "    \"\"\"\n",
        "    # Step 2: Fill numeric columns with median\n",
        "    numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
        "    for col in numeric_columns:\n",
        "        if data[col].isnull().sum() > 0:  # Only fill if there are missing values\n",
        "            data[col] = data[col].fillna(data[col].median())\n",
        "\n",
        "    # Step 3: Fill categorical columns with mode\n",
        "    categorical_columns = data.select_dtypes(include=['object', 'category']).columns\n",
        "    for col in categorical_columns:\n",
        "        if data[col].isnull().sum() > 0:  # Only fill if there are missing values\n",
        "            data[col] = data[col].fillna(data[col].mode()[0])  # Use the most frequent value\n",
        "\n",
        "    return data\n",
        "\n",
        "# Example usage\n",
        "train = handle_missing_values(train, threshold=0.5)\n",
        "\n",
        "# Check the result\n",
        "print(train.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBzr2WhFp5G4"
      },
      "outputs": [],
      "source": [
        "# Example usage\n",
        "test = handle_missing_values(test, threshold=0.5)\n",
        "\n",
        "# Check the result\n",
        "print(train.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhWnHZR4p5G4"
      },
      "outputs": [],
      "source": [
        "train.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XnWc7qsp5G4"
      },
      "outputs": [],
      "source": [
        "train = train.drop(\"Loan_ID\", axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xASbHtmzp5G4"
      },
      "outputs": [],
      "source": [
        "test = test.drop(\"Loan_ID\", axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UrcRfdmp5G5"
      },
      "outputs": [],
      "source": [
        "# Get categorical columns present in the current DataFrame\n",
        "categorical_columns = train.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "# Dictionary to store mappings\n",
        "label_mappings_train = {}\n",
        "\n",
        "\n",
        "for column in categorical_columns:\n",
        "    train[column] = label_encoder.fit_transform(train[column])\n",
        "    label_mappings_train[column] = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HDsV5e9p5G5"
      },
      "outputs": [],
      "source": [
        "# Get categorical columns present in the current DataFrame\n",
        "categorical_columns = test.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "\n",
        "label_mappings_test = {}\n",
        "\n",
        "for column in categorical_columns:\n",
        "    test[column] = label_encoder.fit_transform(test[column])\n",
        "    label_mappings_test[column] = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1ZLWJ34p5G5"
      },
      "outputs": [],
      "source": [
        "# Print the mappings\n",
        "for col, mapping in label_mappings_train.items():\n",
        "    print(f\"Column: {col}\")\n",
        "    print(mapping)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UluL_C9ap5G5"
      },
      "outputs": [],
      "source": [
        "# Print the mappings\n",
        "for col, mapping in label_mappings_test.items():\n",
        "    print(f\"Column: {col}\")\n",
        "    print(mapping)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDPoQmHip5G5"
      },
      "outputs": [],
      "source": [
        "train.head(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ng2DHzXXp5G5"
      },
      "outputs": [],
      "source": [
        "test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Vm3ZeCfp5G5"
      },
      "outputs": [],
      "source": [
        "train[\"ApplicantIncome\"].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6d9KGQ7p5G6"
      },
      "outputs": [],
      "source": [
        "train[\"LoanAmount\"].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4nSr5rihp5G6"
      },
      "outputs": [],
      "source": [
        "'ApplicantIncome\tCoapplicantIncome\tLoanAmount'\n",
        "\n",
        "sns.boxplot(train[\"ApplicantIncome\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvZktiAIp5G6"
      },
      "outputs": [],
      "source": [
        "'ApplicantIncome\tCoapplicantIncome\tLoanAmount'\n",
        "\n",
        "sns.boxplot(train[\"CoapplicantIncome\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwHK7B32p5G6"
      },
      "outputs": [],
      "source": [
        "'ApplicantIncome\tCoapplicantIncome\tLoanAmount'\n",
        "\n",
        "sns.boxplot(train[\"LoanAmount\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gFoSzxRp5G6"
      },
      "outputs": [],
      "source": [
        "unique = train[\"Loan_Amount_Term\"].unique()\n",
        "unique"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_i-95E7p5G6"
      },
      "outputs": [],
      "source": [
        "# Define the numerical columns that need scaling\n",
        "high_num_cols = [\"ApplicantIncome\", \"CoapplicantIncome\", \"LoanAmount\", \"Loan_Amount_Term\"]\n",
        "\n",
        "# Create a copy of the DataFrame (optional, to avoid modifying the original)\n",
        "train_scaled = train.copy()\n",
        "test_scaled = train.copy()\n",
        "\n",
        "# Apply StandardScaler only to the selected numerical columns\n",
        "scaler = StandardScaler()\n",
        "train_scaled[high_num_cols] = scaler.fit_transform(train_scaled[high_num_cols])\n",
        "test_scaled[high_num_cols] = scaler.fit_transform(test_scaled[high_num_cols])\n",
        "\n",
        "# Now df_scaled has the scaled numerical features while categorical ones remain unchanged\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pO-aeFsMp5G6"
      },
      "outputs": [],
      "source": [
        "train_scaled.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8iLVI-u4p5G6"
      },
      "outputs": [],
      "source": [
        "# Plot categorical feature distributions\n",
        "for col in categorical_columns:\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    sns.countplot(y=train_scaled[col], order=train[col].value_counts().index)\n",
        "    plt.title(f\"Distribution of {col}\")\n",
        "    plt.xlabel(\"Count\")\n",
        "    plt.ylabel(col)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GC1WOe8vp5G7"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(train_scaled.corr(), annot=True, fmt=\".2f\", cmap=\"coolwarm\", linewidths=0.5)\n",
        "plt.title(\"Feature Correlation Heatmap\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-oeg2BIp5G7"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(train_scaled, hue=\"Loan_Status\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hy6yJvIGp5G7"
      },
      "outputs": [],
      "source": [
        "# Plot categorical feature distributions\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(y=train_scaled[\"Loan_Status\"], order=train[\"Loan_Status\"].value_counts().index)\n",
        "plt.title(f\"Distribution of Loan_Status\")\n",
        "plt.xlabel(\"Count\")\n",
        "plt.ylabel(\"Loan_Status\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJaGK6xVp5G7"
      },
      "source": [
        "In my experience:\n",
        "When I upsample then split into train test, there is a chance of getting overfit because some of the test values are already seen.\n",
        "\n",
        "But in this we already have the seperate test data we can upsample here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qntDazQfp5G7"
      },
      "outputs": [],
      "source": [
        "# Separate majority and minority classes\n",
        "df_majority = train_scaled[train_scaled[\"Loan_Status\"] == 1]\n",
        "df_minority = train_scaled[train_scaled[\"Loan_Status\"] == 0]\n",
        "\n",
        "# Upsample minority class\n",
        "df_minority_upsampled = resample(df_minority,\n",
        "                                 replace=True,  # Sample with replacement\n",
        "                                 n_samples=len(df_majority),  # Match majority class count\n",
        "                                 random_state=42)  # Ensure reproducibility\n",
        "\n",
        "# Combine majority class with upsampled minority class\n",
        "train_upsample = pd.concat([df_majority, df_minority_upsampled])\n",
        "\n",
        "# Shuffle the dataset\n",
        "train_upsample = train_upsample.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Check class distribution after upsampling\n",
        "print(train_upsample[\"Loan_Status\"].value_counts())\n",
        "\n",
        "# Downsample majority class\n",
        "df_majority_downsampled = resample(df_majority,\n",
        "                                   replace=False,  # No replacement (randomly remove samples)\n",
        "                                   n_samples=len(df_minority),  # Match minority class count\n",
        "                                   random_state=42)  # Ensure reproducibility\n",
        "\n",
        "# Combine minority class with downsampled majority class\n",
        "train_downsample = pd.concat([df_majority_downsampled, df_minority])\n",
        "\n",
        "# Shuffle the dataset\n",
        "train_downsample = train_downsample.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Check class distribution after downsampling\n",
        "print(train_downsample[\"Loan_Status\"].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUjnvV6lp5G7"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(y=train_downsample[\"Loan_Status\"], order=train_downsample[\"Loan_Status\"].value_counts().index)\n",
        "plt.title(f\"Distribution of Loan_Status in downsampled\")\n",
        "plt.xlabel(\"Count\")\n",
        "plt.ylabel(\"Loan_Status\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jujsV0oCp5G8"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(y=train_upsample[\"Loan_Status\"], order=train_upsample[\"Loan_Status\"].value_counts().index)\n",
        "plt.title(f\"Distribution of Loan_Status in upsampled\")\n",
        "plt.xlabel(\"Count\")\n",
        "plt.ylabel(\"Loan_Status\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgwb7LfLp5G8"
      },
      "outputs": [],
      "source": [
        "train_downsample.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-YfLkg6p5HD"
      },
      "outputs": [],
      "source": [
        "train_upsample.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZo1Fhdyp5HD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}